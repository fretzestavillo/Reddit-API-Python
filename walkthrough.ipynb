{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06da2af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting data from reddit using pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_unixtime\n",
    "from pyspark.sql.types import StringType\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from datetime import datetime\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from config import CLIENT_ID, SECRET_KEY\n",
    "\n",
    "with open('pw.txt', 'r') as f:\n",
    "    pw = f.read()\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "data = {\n",
    "    'grant_type': 'password',\n",
    "    'username': 'Electronic-Land-1475',\n",
    "    'password': pw\n",
    "}\n",
    "\n",
    "headers = {'User-Agent': 'MyApi/0.0.1'}\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth, data=data, headers=headers)\n",
    "TOKEN = res.json()['access_token']\n",
    "headers = {**headers, **{'Authorization': f'bearer {TOKEN}'}}\n",
    "\n",
    "res = requests.get('https://oauth.reddit.com/r/python/hot', headers=headers)\n",
    "\n",
    "# Assuming 'created' is a Unix timestamp\n",
    "posts = res.json()['data']['children']\n",
    "\n",
    "# Create a Spark session outside the loop\n",
    "spark = SparkSession.builder.appName(\"RedditPosts\").getOrCreate()\n",
    "\n",
    "# List to store formatted data for each post\n",
    "formatted_data_list = []\n",
    "\n",
    "for post in posts:\n",
    "    # Convert the Unix timestamp to a datetime object\n",
    "    created_timestamp = post['data']['created']\n",
    "\n",
    "    # Convert timestamp to formatted string using the 'yyyy-MM-dd HH:mm:ss' pattern\n",
    "    formatted_created = spark.sql(f\"SELECT from_unixtime({created_timestamp}, 'yyyy-MM-dd HH:mm:ss') as formatted_created\").first().formatted_created\n",
    "\n",
    "    # Create a dictionary with the formatted created time for the current post\n",
    "    formatted_post_data = {\n",
    "        'subreddit': post['data']['subreddit'],\n",
    "        'title': post['data']['title'],\n",
    "        'upvote_ratio': post['data']['upvote_ratio'],\n",
    "        'formatted_created': formatted_created\n",
    "    }\n",
    "\n",
    "    # Append the formatted data for the current post to the list\n",
    "    formatted_data_list.append(formatted_post_data)\n",
    "\n",
    "# Create a Spark DataFrame from the list of dictionaries\n",
    "df = spark.createDataFrame(formatted_data_list)\n",
    "\n",
    "# Show the DataFrame\n",
    "# df.show(50, truncate=False)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# pandas_df = df.toPandas()\n",
    "\n",
    "# upvote_ratio_counts = pandas_df['upvote_ratio'].value_counts().sort_index()\n",
    "\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# upvote_ratio_counts.plot(kind='bar', color='skyblue')\n",
    "# plt.title('Upvote Ratio Distribution')\n",
    "# plt.xlabel('Upvote Ratio')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
